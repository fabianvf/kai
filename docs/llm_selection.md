# LLM Selection

This documentation has moved to the
[editor-extensions](https://github.com/konveyor/editor-extensions) repository.

See the
[sample-provider-settings.yaml](https://github.com/konveyor/editor-extensions/blob/main/vscode/core/resources/sample-provider-settings.yaml)
for LLM provider configuration examples (OpenAI, Azure, Bedrock, DeepSeek,
Gemini, Ollama, and more).
